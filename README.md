# Evaluating the Performance of Different Machine Learning Optimization Frameworks

This repository contains the MSc Artificial Intelligence dissertation project (University of Plymouth, PROJ518).
This repository provides a modular pipeline for training, converting, and benchmarking deep learning models across different optimization frameworks. The goal is to evaluate how frameworks like ONNX Runtime, OpenVINO, TensorFlow Lite, and TorchScript impact model performance.

---

## ðŸ“– Project Overview
This repository contains modular Python scripts for:
- Training of popular CNN architectures: EfficientNetB0, MobileNetV2, ResNet50
- Model Conversion to compatible frameworks styl
- Inference using Keras, ONNX Runtime, TensorFlow Lite, TorchScript, and OpenVINO
- Data Balancing for training and testing splits
- Performance Evaluation with standardized metrics and result logging

---

## ðŸ“Š Dataset
**Fruit Classification Dataset â€“ 10 Classes**
Download the dataset used in this project here:
ðŸ‘‰ [CNN Task: Fruit classification](https://www.kaggle.com/datasets/karimabdulnabi/fruit-classification10-class/data)  

---

## ðŸ“‚ Repository Structure
```
â”œâ”€â”€ Converting_models/ # Scripts for converting trained models
â”œâ”€â”€ Onnx_runtime/ # Inference & evaluation using ONNX Runtime
â”œâ”€â”€ Openvino/ # Inference & evaluation using OpenVINO
â”œâ”€â”€ TFlite/ # Inference & evaluation using TensorFlow Lite
â”œâ”€â”€ Tensorflow_runtime/ # Inference & evaluation with native TensorFlow
â”œâ”€â”€ Torchscript(LLVM)/ # Inference & evaluation using TorchScript
â”œâ”€â”€ Training_scripts/ # Training scripts for CNN models
â”œâ”€â”€ results/ # Benchmark results and evaluation outputs
â””â”€â”€ README.md # Project documentation


